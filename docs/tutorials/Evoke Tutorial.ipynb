{"cells":[{"cell_type":"markdown","id":"80d87512","metadata":{"id":"80d87512"},"source":["# Evoke Tutorial"]},{"cell_type":"markdown","source":["## 1. Introduction"],"metadata":{"id":"XKhJR3mapitL"},"id":"XKhJR3mapitL"},{"cell_type":"markdown","source":["+ [Tutorial](https://colab.research.google.com/drive/1zFRb20KoQi0Tdg5UR1_zReHCZicnQLZd#forceEdit=true&sandboxMode=true) **You are here!** | *Google Colab*\n","+ [Documentation](https://evoke.readthedocs.io/en/latest/) | *ReadTheDocs*\n","+ [Package](https://pypi.org/project/evoke-signals/) | *PyPI*\n","+ [Source code](https://github.com/signalling-games-org/evoke) | *GitHub*\n","\n","**Evoke** is a Python library for evolutionary simulations of signalling games. It is particularly oriented towards reproducing results and figures from the literature, and offers a simple and intuitive API."],"metadata":{"id":"4Dmj832F8fva"},"id":"4Dmj832F8fva"},{"cell_type":"markdown","source":["## 2. Set up"],"metadata":{"id":"q_-a3roufPK-"},"id":"q_-a3roufPK-"},{"cell_type":"markdown","source":["Install Evoke using pip.\n","This can take a little while because package dependencies will be installed too."],"metadata":{"id":"fvjLjOZGfSwW"},"id":"fvjLjOZGfSwW"},{"cell_type":"code","source":["%%capture\n","\n","# Install evoke\n","!pip install evoke_signals"],"metadata":{"id":"8cO5Gq3ufYvl"},"id":"8cO5Gq3ufYvl","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"304dd76f","metadata":{"id":"304dd76f"},"source":["## 3. Creating signalling games"]},{"cell_type":"markdown","id":"f63a7b8c","metadata":{"id":"f63a7b8c"},"source":["### Defining game parameters"]},{"cell_type":"markdown","id":"83220763","metadata":{"id":"83220763"},"source":["You can use Evoke to create your own signalling games and evolutionary simulations.\n","Let's create a very simple 3x3 signalling game with two players.\n","We need four pieces of information to create the game:\n","\n","+ `state_chances`: The number of states the sender can observe, and their probabilities. For this example there will be three equiprobable states.\n","+ `sender_payoff_matrix` and `receiver_payoff_matrix`: Matrices defining the payoffs of sender and receiver. For this example they will be the same: when the state matches the act, both agents get a payoff of 1, otherwise they get a payoff of zero.\n","+ `messages`: The number of messages available for the sender to send, which in this example is three."]},{"cell_type":"code","execution_count":null,"id":"a902c799","metadata":{"id":"a902c799"},"outputs":[],"source":["import numpy as np\n","\n","state_chances = np.array([1/3, 1/3, 1/3])\n","sender_payoff_matrix = np.eye(3)\n","receiver_payoff_matrix = np.eye(3)\n","messages = 3"]},{"cell_type":"markdown","id":"5387d988","metadata":{"id":"5387d988"},"source":["Let's have a look at one of those payoff matrices:"]},{"cell_type":"code","execution_count":null,"id":"a7a8d355","metadata":{"id":"a7a8d355"},"outputs":[],"source":["sender_payoff_matrix"]},{"cell_type":"markdown","id":"d861aeaf","metadata":{"id":"d861aeaf"},"source":["The rows correspond to states and the columns to acts.\n","So when the first act is performed in the first state, the agent gets a payoff of 1, and ditto for the second and third states and acts.\n","Any other combination of state and act yields a payoff of zero."]},{"cell_type":"markdown","id":"e14ac560","metadata":{"id":"e14ac560"},"source":["### Creating the game object"]},{"cell_type":"markdown","id":"4d75fae9","metadata":{"id":"4d75fae9"},"source":["Sender-receiver games have a state that is determined by chance.\n","We therefore need to import the `Chance` class from the `games` module."]},{"cell_type":"code","execution_count":null,"id":"72a14f9b","metadata":{"id":"72a14f9b"},"outputs":[],"source":["from evoke.src.games import Chance"]},{"cell_type":"markdown","id":"46ec5fcb","metadata":{"id":"46ec5fcb"},"source":["We can now create the game object,\n","This is an instance of the `Chance` class, with the game parameters fed into it."]},{"cell_type":"code","execution_count":null,"id":"9cb6e4bb","metadata":{"id":"9cb6e4bb"},"outputs":[],"source":["game = Chance(\n","    state_chances   = state_chances,\n","    sender_payoff_matrix = sender_payoff_matrix,\n","    receiver_payoff_matrix = receiver_payoff_matrix,\n","    messages = messages\n",")"]},{"cell_type":"markdown","id":"8df9d266","metadata":{"id":"8df9d266"},"source":["### Creating the simulation object"]},{"cell_type":"markdown","id":"0c1c5a86","metadata":{"id":"0c1c5a86"},"source":["A game is a static object.\n","It doesn't do anything on its own.\n","To make something happen, we need a set of **strategies** and a means by which those strategies **evolve** according to the payoffs they bring to the agents.\n","\n","Fortunately, the game object already knows all the strategies that are in principle available to an agent:"]},{"cell_type":"code","execution_count":null,"id":"654de954","metadata":{"id":"654de954"},"outputs":[],"source":["sender_strategies = game.sender_pure_strats()\n","receiver_strategies = game.receiver_pure_strats()"]},{"cell_type":"markdown","id":"0e5dfdd8","metadata":{"id":"0e5dfdd8"},"source":["Let's imagine that some senders always send the same signal no matter the state, while others choose a different signal for each state.\n","These correspond to the first and sixth sender strategies (indexed by 0 and 5, because python indexing starts from 0):"]},{"cell_type":"code","execution_count":null,"id":"c950cfc7","metadata":{"id":"c950cfc7"},"outputs":[],"source":["sender_strategies[0] # Pure strategy 0: always send signal 1."]},{"cell_type":"code","execution_count":null,"id":"032aa6b3","metadata":{"id":"032aa6b3"},"outputs":[],"source":["sender_strategies[5] # Pure strategy 5: for all i, send signal i in state i."]},{"cell_type":"markdown","id":"5c1b6058","metadata":{"id":"5c1b6058"},"source":["So, we will construct a population with just these two strategies, along with the corresponding strategies for the receiver:"]},{"cell_type":"code","execution_count":null,"id":"b32a7db0","metadata":{"id":"b32a7db0"},"outputs":[],"source":["sender_population = np.array(\n","    [sender_strategies[0],sender_strategies[5]] # An array of strategies i.e. an array of matrices\n",")\n","\n","receiver_population = np.array(\n","    [receiver_strategies[0],receiver_strategies[5]] # An array of strategies i.e. an array of matrices\n",")"]},{"cell_type":"markdown","id":"0c277063","metadata":{"id":"0c277063"},"source":["...and we can evolve a population playing some mixture of these strategies using an appropriate simulation object from the `evolve` module:"]},{"cell_type":"code","execution_count":null,"id":"a51cf9d5","metadata":{"id":"a51cf9d5"},"outputs":[],"source":["from evoke.src.evolve import TwoPops # One population of senders, one population of receivers\n","\n","# Create the simulation object\n","evo = TwoPops(game, sender_population, receiver_population)"]},{"cell_type":"markdown","id":"893a814e","metadata":{"id":"893a814e"},"source":["Let's see what happens when we evolve these populations."]},{"cell_type":"code","execution_count":null,"id":"c0820d15","metadata":{"id":"c0820d15"},"outputs":[],"source":["# Define equiprobable strategies\n","sender_strategy_vector = receiver_strategy_vector = np.array([1/2,1/2])\n","\n","# Get a population vector in the format evo expects it\n","population_vector = np.concatenate((sender_strategy_vector, receiver_strategy_vector))\n","\n","# For 100 iterations, get the new population vector\n","population_vectors_over_time = np.array([population_vector]) # this will store information about how the population changes\n","for _ in range(100):\n","\n","    # Get the population vector at the next step\n","    population_vector = evo.discrete_replicator_delta_X(population_vector)\n","\n","    # Store the population vector\n","    population_vectors_over_time = np.vstack((population_vectors_over_time,np.array([population_vector])))"]},{"cell_type":"markdown","id":"28420bc9","metadata":{"id":"28420bc9"},"source":["Now `population_vectors_over_time` is a big list of how many of each type of sender and receiver there was at each step of the simulation.\n","Let's plot the change in the two sender types:"]},{"cell_type":"code","execution_count":null,"id":"839a21c6","metadata":{"id":"839a21c6"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","\n","# Get the proportions of each sender type as it changes over time\n","sender_type_ignorant_time_series = population_vectors_over_time.T[0]\n","sender_type_responsive_time_series = population_vectors_over_time.T[1]\n","\n","# Create the plot\n","plt.plot(range(len(population_vectors_over_time)),sender_type_ignorant_time_series,label=\"Ignorant sender\")\n","plt.plot(range(len(population_vectors_over_time)),sender_type_responsive_time_series,label=\"Responsive sender\")\n","\n","# Add a legend\n","plt.legend()\n","\n","# Add axis labels\n","plt.xlabel(\"Generations\")\n","plt.ylabel(\"Proportion of sender type\")\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"markdown","id":"227d87b7","metadata":{"id":"227d87b7"},"source":["The ignorant sender very quickly drops to zero, while the responsive sender very quickly dominates."]},{"cell_type":"markdown","id":"4673bc88","metadata":{"id":"4673bc88"},"source":["## 4. Recreating figures from the literature"]},{"cell_type":"markdown","id":"91b58338","metadata":{"id":"91b58338"},"source":["### Creating figures; tweaking cosmetic features"]},{"cell_type":"markdown","id":"e1a3ae72","metadata":{"id":"e1a3ae72"},"source":["Suppose you want to recreate Figure 1.1 from page 11 of *Signals* (Skyrms 2010).\n","The figure depicts the evolutionary dynamics of a 2x2 sender-receiver game.\n","The x-axis gives the proportion of receivers mapping the first signal to the second act and the second signal to the first act.\n","The y-axis gives the proportion of senders mapping the first state to the second signal and the second state to the first signal.\n","\n","The points at which the population is achieving the greatest coordination are thus (0,0) and (1,1), so we would expect to see the arrows in the grid pointing towards those two corners.\n","Skyrms's figure shows exactly that.\n","\n","For copyright reasons we can't show the original figure here.\n","Fortunately, recreating the figure is as easy as importing the relevant class and creating an instance of it:"]},{"cell_type":"code","execution_count":null,"id":"afa8b4fc-a835-42d5-bba5-37b0d0ef51ab","metadata":{"id":"afa8b4fc-a835-42d5-bba5-37b0d0ef51ab","tags":[]},"outputs":[],"source":["# Import the class\n","from evoke.examples.skyrms2010signals import Skyrms2010_1_1\n","\n","# Create an instance of the class\n","fig1_1 = Skyrms2010_1_1()"]},{"cell_type":"markdown","id":"90f68fa9","metadata":{"id":"90f68fa9"},"source":["If you check page 11 of _Signals_ you will see this plot closely matches Figure 1.1.\n","\n","Let's say you don't like the boring black arrows and want them to be blue instead.\n","The figure you just created has various customisable options.\n","Change the `color` attribute, and Evoke will automatically rebuild the plot:"]},{"cell_type":"code","execution_count":null,"id":"0a721ff7","metadata":{"id":"0a721ff7"},"outputs":[],"source":["fig1_1.color = \"blue\""]},{"cell_type":"markdown","id":"de79b80e","metadata":{"id":"de79b80e"},"source":["Now suppose you're appalled at the lack of axis labels.\n","You can add them like standard class attributes.\n","The figure would again be instantly recreated..."]},{"cell_type":"code","execution_count":null,"id":"80f316c5","metadata":{"id":"80f316c5"},"outputs":[],"source":["fig1_1.show_immediately = False # Let's not create two new plots...\n","fig1_1.xlabel = \"Proportion of receivers playing R2\"\n","fig1_1.ylabel = \"Proportion of senders playing R2\""]},{"cell_type":"markdown","id":"66bad377","metadata":{"id":"66bad377"},"source":["...except that we suppressed the immediate output upon changing an attribute by first setting `fig1_1.show_immediately = False`.\n","Without this, the code would have created two new figures, one after the setting of `fig1_1.xlabel` and one after `fig1_1.ylabel`.\n","\n","To show the figure manually, just call `show()`:"]},{"cell_type":"code","source":["fig1_1.show() #... let's just create one manually."],"metadata":{"id":"MPesOlQbklUw"},"id":"MPesOlQbklUw","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Some figures look better without axes at all.\n","Skyrms' second figure is an example.\n","It depicts the same 2x2 game, this time with a single population of agents that can play either sender or receiver in each round.\n","The evolutionary dynamics belong in a tetrahedron; the two stable points are at two vertices, with one or the other of the two strategies dominating:"],"metadata":{"id":"cwn5kCfRklyu"},"id":"cwn5kCfRklyu"},{"cell_type":"code","execution_count":null,"id":"3fdb2dca","metadata":{"id":"3fdb2dca"},"outputs":[],"source":["from evoke.examples.skyrms2010signals import * # import all figures from Skyrms\n","\n","fig1_2 = Skyrms2010_1_2() # Create figure 1.2"]},{"cell_type":"markdown","id":"273a6a12","metadata":{"id":"273a6a12"},"source":["If you want to see the axes, just switch `noaxis` to `False`:"]},{"cell_type":"code","execution_count":null,"id":"8a1f1f15","metadata":{"id":"8a1f1f15"},"outputs":[],"source":["fig1_2.noaxis = False"]},{"cell_type":"markdown","id":"e1f57d9d","metadata":{"id":"e1f57d9d"},"source":["I know what you're thinking, and the answer is yes, you can make the arrows blue."]},{"cell_type":"code","execution_count":null,"id":"d9c99464","metadata":{"id":"d9c99464"},"outputs":[],"source":["fig1_2.color = \"blue\""]},{"cell_type":"markdown","id":"447auK7zpywp","metadata":{"id":"447auK7zpywp"},"source":["To get a list of all the editable properties of a figure along with their current values, look at the `properties` property.\n","In addition to `noaxis` and `color`, we see that we can add axis labels to all three axes:"]},{"cell_type":"code","execution_count":null,"id":"h9rbJKwIp0Nj","metadata":{"id":"h9rbJKwIp0Nj"},"outputs":[],"source":["fig1_2.properties"]},{"cell_type":"markdown","id":"00b0a0f5","metadata":{"id":"00b0a0f5"},"source":["### Changing data in figures"]},{"cell_type":"markdown","id":"b1bceaf8","metadata":{"id":"b1bceaf8"},"source":["One of the useful features of Evoke is that it allows you to re-run existing figures with different data.\n","In this way you can see how the results of a simulation would change if the parameters were tweaked.\n","\n","Let's take figure 3.3 of Skyrms (2010:40) as an example.\n","This figure plots the increase in information carried by a signal over time, with agents using reinforcement learning to develop coordinated signalling and response strategies.\n","\n","Once again we can create the basic figure just by creating an instance of the object:"]},{"cell_type":"code","execution_count":null,"id":"f1d27038","metadata":{"id":"f1d27038"},"outputs":[],"source":["fig3_3 = Skyrms2010_3_3()"]},{"cell_type":"markdown","id":"be42bd33","metadata":{"id":"be42bd33"},"source":["(Figures like this rely on randomisation, so the figure above might look a little different from how it does in the book. You can run the code block multiple times to get a sense of the possible variations.)\n","\n","The basic figure shows what happens after 100 iterations.\n","Let's say we want to see what happens after 1000:"]},{"cell_type":"code","execution_count":null,"id":"1eac0638","metadata":{"id":"1eac0638"},"outputs":[],"source":["fig3_3 = Skyrms2010_3_3(iterations=1000)"]},{"cell_type":"markdown","id":"a193a055","metadata":{"id":"a193a055"},"source":["Even if 100 iterations was not enough to generate appreciable information transmission between agents, 1000 iterations very likely will be."]},{"cell_type":"markdown","id":"a458e7ab","metadata":{"id":"a458e7ab"},"source":["## 5. Adding to the stock of figures"]},{"cell_type":"markdown","id":"53e6b154","metadata":{"id":"53e6b154"},"source":["You might want to add figures from the literature that aren't part of Evoke's example library yet.\n","If so, thanks!\n","We hope to expand the set of examples so that Evoke can become a place to test modelling assumptions and play around with data.\n","\n","The following are simple steps to contribute to Evoke.\n","For more detailed instructions see the dedicated [CONTRIBUTING.md](https://github.com/signalling-games-org/evoke/blob/main/CONTRIBUTING.md) document."]},{"cell_type":"markdown","id":"6loIx9779q_6","metadata":{"id":"6loIx9779q_6"},"source":["### Fork the repository\n","\n","First, fork the [Evoke](https://github.com/signalling-games-org/evoke) repository."]},{"cell_type":"markdown","id":"bd2ab2a9","metadata":{"id":"bd2ab2a9"},"source":["### Create a script\n","\n","To add an example, create a new script whose name is the same format as the others in the `evoke/examples/` directory i.e. the first author's surname, the year, and the first word of the publication's title, all in lower case and without breaks or punctuation.\n","So for example Skyrms's book *Signals*, published in 2010, becomes `skyrms2010signals.py`.\n","The paper 'Communication and Common Interest' by Godfrey-Smith and Martínez becomes `godfreysmith2013communication.py`."]},{"cell_type":"markdown","id":"a9e9af58","metadata":{"id":"a9e9af58"},"source":["### Subclass from `figure.py`\n","\n","Inside your script, create an object with the name formatted `SurnameYear_figure_number`.\n","For example, figure 4.1 of Skyrms (2010) is called `Skyrms2010_4_1`.\n","\n","This object **must** subclass from one of the classes defined in `figure.py`.\n","If necessary, add a new class definition in `figure.py` first."]},{"cell_type":"markdown","id":"d713645e","metadata":{"id":"d713645e"},"source":["### Add custom code\n","\n","Add your custom code in the object you just created.\n","Take a look at the existing examples to get a feel for how this works."]},{"cell_type":"markdown","id":"bvDFt79i9U2D","metadata":{"id":"bvDFt79i9U2D"},"source":["### Pull request\n","\n","When you've tested and everything looks good, create a pull request from your fork."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":5}